{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "4장 모델 훈련 과제 2017250044 정재현",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/g202jh/machinelearning-text/blob/master/4%EC%9E%A5_%EB%AA%A8%EB%8D%B8_%ED%9B%88%EB%A0%A8_%EA%B3%BC%EC%A0%9C_2017250044_%EC%A0%95%EC%9E%AC%ED%98%84.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BCOlzXvJLQ3"
      },
      "source": [
        "## 기본 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eZaSGEdYSNl"
      },
      "source": [
        "# 파이썬 ≥3.5 필수\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# 사이킷런 ≥0.20 필수\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# 공통 모듈 임포트\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# 노트북 실행 결과를 동일하게 유지하기 위해\n",
        "np.random.seed(42)\n",
        "\n",
        "# 깔끔한 그래프 출력을 위해\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# 그림을 저장할 위치\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"training_linear_models\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"그림 저장:\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "    \n",
        "# 어레이 데이터를 csv 파일로 저장하기\n",
        "def save_data(fileName, arrayName, header=''):\n",
        "    np.savetxt(fileName, arrayName, delimiter=',', header=header, comments='')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l0YO6guYSOZ"
      },
      "source": [
        "#과제"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5eC3vurYSOZ"
      },
      "source": [
        "## 과제 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l46254exYSOZ"
      },
      "source": [
        "조기 종료를 사용한 배치 경사 하강법으로 로지스틱 회귀를 구현하라.\n",
        "단, 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwWc-8wZrsYh"
      },
      "source": [
        "__단계 1: 데이터 준비__ \n",
        "\n",
        "붓꽃 데이터셋의 꽃잎 길이와 꽃잎 너비 특성만 이용한다.\n",
        "\n",
        "꽃의 품종이 버지니카인지 아닌지 판별할 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRJbFl0_ux25"
      },
      "source": [
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJtpqm8orVkE",
        "outputId": "8ca34f7b-a57c-49db-d2cd-6b489586d4c6"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "La9F7OATrr4S"
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = (iris[\"target\"] == 2).astype(np.int)  # 버지니카(Virginica) 품종일 때 1(양성)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWkR0movshqW"
      },
      "source": [
        "0번특성값을 x0이라 판단하기때문에 편향을 추가해야한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OGDa3hxsAvs"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PF9yyDRsCCe"
      },
      "source": [
        "결과를 일정하게 유지하기 위해 랜덤 시드를 지정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xOn3OlFsFkp"
      },
      "source": [
        "np.random.seed(2042)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIza9n6dsHTK"
      },
      "source": [
        "__단계 2: 데이터셋 분할__ \n",
        "\n",
        "데이터셋을 훈련, 검증, 테스트 용도로 6대 2대 2의 비율로 무작위로 분할한다.\n",
        "\n",
        "- 훈련 세트: 60%\n",
        "- 검증 세트: 20%\n",
        "- 테스트 세트: 20%\n",
        "\n",
        "아래 코드는 사이킷런의 train_test_split() 함수를 사용하지 않고 \n",
        "수동으로 무작위 분할하는 방법을 보여준다.\n",
        "먼저 각 세트의 크기를 결정한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqm-8HDGsKyV"
      },
      "source": [
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvvVHKdtyetB"
      },
      "source": [
        "np.random.permutation() 함수를 이용하여 인덱스를 무작위로 섞는다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQFKYejgygxV"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8h-njfqjyjEl"
      },
      "source": [
        "인덱스가 무작위로 섞였기 때문에 무작위로 분할하는 효과를 얻는다.\n",
        "방법은 섞인 인덱스를 이용하여 지정된 6:2:2의 비율로 훈련, 검증, 테스트 세트로 분할하는 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OE5FcTa1ylTT"
      },
      "source": [
        "X_train = X_with_bias[rnd_indices[:train_size]]\n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tdl3CjXDrq_C",
        "outputId": "b2b6f204-940d-45c7-b65c-53da23a1f4cd"
      },
      "source": [
        "y_train[:5]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbPKa-wIypm3"
      },
      "source": [
        "__단계 3: 로지느틱 모델 구현__ \n",
        "\n",
        "먼저 로지스틱에 사용되는 시그모이드 함수를 만든다.\n",
        "\n",
        "$$\n",
        "\\sigma(t) = \\frac{1}{1 + e^{-t}}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cttL3rdS2A6Z"
      },
      "source": [
        "def logistic(logits):\n",
        "    return 1.0 / (1 + np.exp(-logits))                         "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_q328c36bA3"
      },
      "source": [
        "__단계 5: 경사하강법 활용 훈련__ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foampRBpsZOr"
      },
      "source": [
        "가중치를 조정해나가기 위한 세타를 생성한다. 초기값은 랜덤이다.\n",
        "\n",
        "여기에서 n은 특성이 두개이므로 2가된다.\n",
        "\n",
        "$$\n",
        "\\begin{align*}\n",
        "\\hat y^{(i)} & = \\theta^{T}\\, \\mathbf{x}^{(i)} \\\\\n",
        " & = \\theta_0 + \\theta_1\\, \\mathbf{x}_1^{(i)} + \\cdots + \\theta_n\\, \\mathbf{x}_n^{(i)}\n",
        "\\end{align*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QC7X5Yp7vsb"
      },
      "source": [
        "n_inputs = X_train.shape[1] #편향과 특성의 갯수\n",
        "Theta = np.random.randn(n_inputs) #편향과 특성의 갯수만큼 세타값 랜덤초기화"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwM32VHjsfA-"
      },
      "source": [
        "**비용함수 구현**\n",
        "\n",
        "$$\n",
        "J(\\boldsymbol{\\theta}) = -\\dfrac{1}{m} \\sum\\limits_{i=1}^{m}{\\left[ y^{(i)} log\\left(\\hat{p}^{(i)}\\right) + (1 - y^{(i)}) log\\left(1 - \\hat{p}^{(i)}\\right)\\right]}\n",
        "$$\n",
        "\n",
        "위의 수식을 코드로 표현하면 다음과 같다.\n",
        "\n",
        "-np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lN-iEO4748k"
      },
      "source": [
        "배치 경사하강법 훈련은 아래 코드를 통해 이루어진다.\n",
        "\n",
        "- `eta = 0.01`: 학습률\n",
        "- `n_iterations = 5001` : 에포크 수\n",
        "- `m = len(X_train)`: 훈련 세트 크기, 즉 훈련 샘플 수\n",
        "- `epsilon = 1e-7`: $\\log$ 값이 항상 계산되도록 더해지는 작은 실수\n",
        "- `logits`: 모든 샘플에 대한 클래스별 점수, 즉 $\\mathbf{X}_{\\textit{train}}\\, \\Theta$\n",
        "- `Y_proba`: 모든 샘플에 대해 계산된 클래스 별 소속 확률, 즉 $\\hat P$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILnPAFhw77Ij",
        "outputId": "00290c43-f343-4d8a-d734-bb71dd21385d"
      },
      "source": [
        "#  배치 경사하강법 구현\n",
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "\n",
        "for iteration in range(n_iterations):     # 5001번 반복 훈련\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "   \n",
        "    if iteration % 500 == 0:\n",
        "      loss = -np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))\n",
        "      print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba - y_train     # 그레이디언트 계산.\n",
        "    gradients = 1/m * X_train.T.dot(error)\n",
        "    \n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 79.35473984499612\n",
            "500 27.149524631560638\n",
            "1000 21.89438928577945\n",
            "1500 19.33777344771706\n",
            "2000 17.691444239326714\n",
            "2500 16.49516908325313\n",
            "3000 15.566000472955372\n",
            "3500 14.81327398979558\n",
            "4000 14.185530546071131\n",
            "4500 13.65075154805576\n",
            "5000 13.187653637231028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3h8h5Cy8Tl1"
      },
      "source": [
        "학습된 파라미터는 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJiD9wiv8VmW",
        "outputId": "4e1a8a84-da5d-4f44-ba26-adf98121c608"
      },
      "source": [
        "Theta"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-10.56492618,   0.53611169,   4.82694082])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-L837cJtL5O"
      },
      "source": [
        "**검증**\n",
        "\n",
        "위에서 얻은 세타값을 가지고\n",
        "검증세트로 모델 성능을 판단한다.\n",
        "\n",
        "Y_proba값이 0.5 이상이라면 버지니아로, 아니라면 버지니아가 아니라고 입력해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z7O19Cf8Y_I",
        "outputId": "7a7b04e2-b6c7-4108-e85d-d6060337adc3"
      },
      "source": [
        "logits = X_valid.dot(Theta)              \n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.array([])\n",
        "for i in range(len(Y_proba)):\n",
        "  if Y_proba[i] >= 0.5:\n",
        "    y_predict = np.append(y_predict, 1)\n",
        "  else:\n",
        "    y_predict = np.append(y_predict, 0)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)  # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4-ZavgttQSc"
      },
      "source": [
        "직접 데이터를 구해보면"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWdULJBOtSzK",
        "outputId": "a82592ba-a2dd-4fc6-f7d6-d8279c876f0d"
      },
      "source": [
        "y_predict"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1.,\n",
              "       0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_QZrmeNtUI9",
        "outputId": "949ca671-6843-4cc2-9eef-a8089d28e2e5"
      },
      "source": [
        "y_valid"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCW9mnKmiIA3"
      },
      "source": [
        "__단계 6: 규제가 추가된 경사하강법 활용 훈련__ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBfmAOATiRoH",
        "outputId": "bb55179a-200a-4191-96ba-f294ff78568a"
      },
      "source": [
        "eta = 0.1\n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5        # 규제 하이퍼파라미터\n",
        "\n",
        "Theta = np.random.randn(n_inputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    \n",
        "    if iteration % 500 == 0:\n",
        "        xentropy_loss = -np.mean(np.sum((y_train*np.log(Y_proba + epsilon) + (1-y_train)*np.log(1 - Y_proba + epsilon))))\n",
        "        l2_loss = 1/2 * np.sum(np.square(Theta[1:]))  # 편향은 규제에서 제외\n",
        "        loss = xentropy_loss + alpha * l2_loss        # l2 규제가 추가된 손실\n",
        "        print(iteration, loss)\n",
        "    \n",
        "    error = Y_proba - y_train\n",
        "    l2_loss_gradients = np.r_[np.zeros([1]), alpha * Theta[1:]]   # l2 규제 그레이디언트\n",
        "    gradients = 1/m * X_train.T.dot(error) + l2_loss_gradients\n",
        "    \n",
        "    Theta = Theta - eta * gradients"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 156.73838246234882\n",
            "500 36.11974638424874\n",
            "1000 34.306068180110614\n",
            "1500 34.02211206089248\n",
            "2000 33.9713877223945\n",
            "2500 33.96211929178583\n",
            "3000 33.96041878356459\n",
            "3500 33.960106551185575\n",
            "4000 33.96004921390298\n",
            "4500 33.96003868441418\n",
            "5000 33.96003675075696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQtfb2q7irHA"
      },
      "source": [
        "검증세트에 규제를 적용하니 정확도가 미미하게 떨어졌다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsbClH2Fia_T",
        "outputId": "7a67dba7-9898-4558-96f1-c551b2ac045f"
      },
      "source": [
        "logits = X_valid.dot(Theta)              \n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.array([])\n",
        "for i in range(len(Y_proba)):\n",
        "  if Y_proba[i] >= 0.5:\n",
        "    y_predict = np.append(y_predict, 1)\n",
        "  else:\n",
        "    y_predict = np.append(y_predict, 0)\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_valid)  # 정확도 계산\n",
        "accuracy_score"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8333333333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y_kv5vnuWcD"
      },
      "source": [
        "점수가 조금 떨어졌으나 중요한것은 테스트세트에 대한 성능이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaJgbA3EixHq"
      },
      "source": [
        "__단계 7: 조기 종료 추가__\n",
        "\n",
        "조기종료는 검증세트에 대한 손실값이 이전 단계보다 커지면\n",
        "바로 종료되는 기능이다. 이를 코드로 구현하면 다음과 같다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3ONEOAVi0r-",
        "outputId": "f59f29b6-641a-4d4c-c399-57791d0d2279"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 50000\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5            # 규제 하이퍼파라미터\n",
        "best_loss = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta = np.random.randn(n_inputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits = X_train.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    error = Y_proba - y_train\n",
        "    gradients = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1]), alpha * Theta[1:]]\n",
        "    Theta = Theta - eta * gradients\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits = X_valid.dot(Theta)\n",
        "    Y_proba = logistic(logits)\n",
        "    xentropy_loss = -np.mean(np.sum((y_valid*np.log(Y_proba + epsilon) + (1-y_valid)*np.log(1 - Y_proba + epsilon))))\n",
        "    l2_loss = 1/2 * np.sum(np.square(Theta[1:]))\n",
        "    loss = xentropy_loss + alpha * l2_loss\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss < best_loss:\n",
        "        best_loss = loss\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss)        # 종료되기 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 31.861885822665705\n",
            "500 12.54052343500867\n",
            "1000 11.955093912404864\n",
            "1500 11.865469014733975\n",
            "2000 11.849523658203214\n",
            "2500 11.846612260301496\n",
            "3000 11.846078169747395\n",
            "3500 11.845980107187028\n",
            "4000 11.845962099397736\n",
            "4500 11.845958792428052\n",
            "5000 11.84595818512936\n",
            "5500 11.845958073603674\n",
            "6000 11.84595805312284\n",
            "6500 11.845958049361693\n",
            "7000 11.845958048670985\n",
            "7500 11.845958048544144\n",
            "8000 11.845958048520849\n",
            "8351 11.845958048517204\n",
            "8352 11.845958048517206 조기 종료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hkyn8RUYuqtl"
      },
      "source": [
        "__단계 8: 테스트 세트 평가__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGhSiSaUjFAm",
        "outputId": "0e2f550d-4f02-4446-c9a6-07b0e25eda90"
      },
      "source": [
        "logits = X_test.dot(Theta)\n",
        "Y_proba = logistic(logits)\n",
        "y_predict = np.array([])\n",
        "for i in range(len(Y_proba)):\n",
        "  if Y_proba[i] >= 0.5:\n",
        "    y_predict = np.append(y_predict, 1)\n",
        "  else:\n",
        "    y_predict = np.append(y_predict, 0)\n",
        "\n",
        "\n",
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9666666666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy_A9hUrYSOZ"
      },
      "source": [
        "## 과제 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-MBSevIYSOa"
      },
      "source": [
        "과제 1에서 구현된 로지스틱 회귀 알고리즘에 일대다(OvR) 방식을 적용하여 붓꽃에 대한 다중 클래스 분류 알고리즘을 구현하라. 단, 사이킷런을 전혀 사용하지 않아야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xdjf7a4_vcN8"
      },
      "source": [
        "과제2를 수행하기 위해서는 로지스틱 모델을 2개를 사용해야한다. \n",
        "\n",
        "먼저 setosa인지 아닌지를 판단하는 모델\n",
        "\n",
        "그리고 virginica인지 아닌지를 판단하는 모델을 각각 만든후에\n",
        "\n",
        "versicolor일 확률 = '1 - setosa일 확률 - virginica일 확률'로 계산해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6Xp3V4FZvJe"
      },
      "source": [
        "X = iris[\"data\"][:, (2, 3)]  # 꽃잎 길이, 꽃잎 넓이\n",
        "y = iris[\"target\"]\n",
        "y0 = (iris[\"target\"] == 0).astype(np.int) #setosa 판단 모델을 위한 데이터셋\n",
        "y1 = (iris[\"target\"] == 2).astype(np.int) #virginica 판단 모델을 위한 데이터셋"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcAAMVJxaVdK"
      },
      "source": [
        "X_with_bias = np.c_[np.ones([len(X), 1]), X] #편향추가"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1j2vbxLMaW3X"
      },
      "source": [
        "np.random.seed(2042) #일정한 결과를 위해 랜덤시드 지정"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DO1pf77maea6"
      },
      "source": [
        "test_ratio = 0.2                                         # 테스트 세트 비율 = 20%\n",
        "validation_ratio = 0.2                                   # 검증 세트 비율 = 20%\n",
        "total_size = len(X_with_bias)                            # 전체 데이터셋 크기\n",
        "\n",
        "test_size = int(total_size * test_ratio)                 # 테스트 세트 크기: 전체의 20%\n",
        "validation_size = int(total_size * validation_ratio)     # 검증 세트 크기: 전체의 20%\n",
        "train_size = total_size - test_size - validation_size    # 훈련 세트 크기: 전체의 60%"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2mvx5Jqaf-g"
      },
      "source": [
        "rnd_indices = np.random.permutation(total_size) #데이터 섞기"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb0bLyrdwNVX"
      },
      "source": [
        "모델 훈련은 각 클래스에 대해 각각 이루어지기 때문에 데이터셋도 각각 준비해준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLIg7WA9ahlV"
      },
      "source": [
        "X_train = X_with_bias[rnd_indices[:train_size]] \n",
        "y_train = y[rnd_indices[:train_size]]\n",
        "y_train0 = y0[rnd_indices[:train_size]] #setosa에 대한 라벨\n",
        "y_train1 = y1[rnd_indices[:train_size]] #virginica에 대한 라벨\n",
        "\n",
        "X_valid = X_with_bias[rnd_indices[train_size:-test_size]]\n",
        "y_valid = y[rnd_indices[train_size:-test_size]]\n",
        "y_valid0 = y0[rnd_indices[train_size:-test_size]] #setosa에 대한 검증세트 라벨\n",
        "y_valid1 = y1[rnd_indices[train_size:-test_size]] #virginica에 대한 검증세트 라벨\n",
        "\n",
        "X_test = X_with_bias[rnd_indices[-test_size:]]\n",
        "y_test = y[rnd_indices[-test_size:]]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efv7DUsJwXDW"
      },
      "source": [
        "n_inputs = X_train.shape[1]\n",
        "Theta0 = np.random.randn(n_inputs) #setosa 판단모델에 쓰이는 세타값\n",
        "Theta1 = np.random.randn(n_inputs) #virginica 판단모델에 쓰이는 세타값"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3-6djjswcMQ"
      },
      "source": [
        "**setosa 판별 로지스틱 회귀 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aFqb8oTdPDV",
        "outputId": "7d9ac9cd-9c81-4c67-9925-47f6a79a6dfc"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5            # 규제 하이퍼파라미터\n",
        "best_loss0 = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta0 = np.random.randn(n_inputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits0 = X_train.dot(Theta0)\n",
        "    Y_proba0 = logistic(logits0)\n",
        "    error = Y_proba0 - y_train0\n",
        "    gradients0 = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1]), alpha * Theta0[1:]]\n",
        "    Theta0 = Theta0 - eta * gradients0\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits0 = X_valid.dot(Theta0)\n",
        "    Y_proba0 = logistic(logits0)\n",
        "    xentropy_loss0 = -np.mean(np.sum((y_valid0*np.log(Y_proba0 + epsilon) + (1-y_valid0)*np.log(1 - Y_proba0 + epsilon))))\n",
        "    l2_loss0 = 1/2 * np.sum(np.square(Theta0[1:]))\n",
        "    loss0 = xentropy_loss0 + alpha * l2_loss0\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss0)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss0 < best_loss0:\n",
        "        best_loss0 = loss0\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss0)        # 종료되기 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss0, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 20.540019459712514\n",
            "500 7.744571615343959\n",
            "1000 7.672989036271927\n",
            "1500 7.668592640555666\n",
            "2000 7.668314272027711\n",
            "2500 7.668296612120626\n",
            "3000 7.668295491624586\n",
            "3500 7.668295420530142\n",
            "4000 7.668295416019264\n",
            "4500 7.668295415733049\n",
            "5000 7.668295415714894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf3PYjEkwlX_"
      },
      "source": [
        "**virginica 판별 로지스틱 회귀 모델**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHF8Il3FdjOw",
        "outputId": "e40e27d5-e091-4571-9252-611b7e786c90"
      },
      "source": [
        "eta = 0.1 \n",
        "n_iterations = 5001\n",
        "m = len(X_train)\n",
        "epsilon = 1e-7\n",
        "alpha = 0.5            # 규제 하이퍼파라미터\n",
        "best_loss1 = np.infty   # 최소 손실값 기억 변수\n",
        "\n",
        "Theta1 = np.random.randn(n_inputs)  # 파라미터 새로 초기화\n",
        "\n",
        "for iteration in range(n_iterations):\n",
        "    # 훈련 및 손실 계산\n",
        "    logits1 = X_train.dot(Theta1)\n",
        "    Y_proba1 = logistic(logits1)\n",
        "    error = Y_proba1 - y_train1\n",
        "    gradients1 = 1/m * X_train.T.dot(error) + np.r_[np.zeros([1]), alpha * Theta1[1:]]\n",
        "    Theta1 = Theta1 - eta * gradients1\n",
        "\n",
        "    # 검증 세트에 대한 손실 계산\n",
        "    logits1 = X_valid.dot(Theta1)\n",
        "    Y_proba1 = logistic(logits1)\n",
        "    xentropy_loss1 = -np.mean(np.sum((y_valid1*np.log(Y_proba1 + epsilon) + (1-y_valid1)*np.log(1 - Y_proba1 + epsilon))))\n",
        "    l2_loss1 = 1/2 * np.sum(np.square(Theta1[1:]))\n",
        "    loss1 = xentropy_loss1 + alpha * l2_loss1\n",
        "    \n",
        "    # 500 에포크마다 검증 세트에 대한 손실 출력\n",
        "    if iteration % 500 == 0:\n",
        "        print(iteration, loss1)\n",
        "        \n",
        "    # 에포크마다 최소 손실값 업데이트\n",
        "    if loss1 < best_loss1:\n",
        "        best_loss1 = loss1\n",
        "    else:                                      # 에포크가 줄어들지 않으면 바로 훈련 종료\n",
        "        print(iteration - 1, best_loss1)        # 종료되기 이전 에포크의 손실값 출력\n",
        "        print(iteration, loss1, \"조기 종료!\")\n",
        "        break"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 45.38818486389959\n",
            "500 12.482904005693054\n",
            "1000 11.947222069327108\n",
            "1500 11.864096195806566\n",
            "2000 11.849273910674974\n",
            "2500 11.846566475123907\n",
            "3000 11.846069764314986\n",
            "3500 11.845978563684064\n",
            "4000 11.845961815948371\n",
            "4500 11.845958740374874\n",
            "5000 11.845958175570198\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAyT1EGjwtjG"
      },
      "source": [
        "**이제 테스트셋에 적용해본다.**\n",
        "\n",
        "위에서 구한 두개의 세타값을 이용해\n",
        "\n",
        "1.   setosa일 확률(setosa_proba)\n",
        "2.   virginica일 확률(virginica_proba)\n",
        "3.   versicolor일 확률(1 - setosa_proba - virginica_proba)\n",
        "\n",
        "셋중에 가장 높은것을 채택하여 분류를 진행한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-CLu5-OuFc8"
      },
      "source": [
        "logits = X_test.dot(Theta0) #setosa에 대한 확률값 추정  \n",
        "setosa_proba = logistic(logits)\n",
        "\n",
        "logits = X_test.dot(Theta1) #virginica에 대한 확률값 추정 \n",
        "virginica_proba = logistic(logits)\n",
        "\n",
        "y_predict = np.array([])\n",
        "for i in range(len(Y_proba0)):\n",
        "  prob_list = [[setosa_proba[i], 0], [1-setosa_proba[i]-virginica_proba[i], 1], [virginica_proba[i], 2]]\n",
        "  prob_list.sort(reverse=True) #가장 높은 확률이 가장 앞으로 오게끔 정렬해준다.\n",
        "  y_predict = np.append(y_predict, prob_list[0][1]) #가장 확률이 높았던 것을 예측값으로 결정한다."
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnhaeNakwzaH",
        "outputId": "e1021685-f943-4a9b-ad95-9c823a827b95"
      },
      "source": [
        "accuracy_score = np.mean(y_predict == y_test)\n",
        "accuracy_score"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9333333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Yh1HLrYYSOa"
      },
      "source": [
        "## 과제 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMzBmU_oYSOa"
      },
      "source": [
        "A. 사진을 낮과 밤으로 분류하는 로지스틱 회귀 모델을 구현하라."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJE0gFUeYSOa"
      },
      "source": [
        "B. 사진을 낮과 밤, 실내와 실외로 분류하는 다중 레이블 분류 모델을 두 개의 로지스틱 회귀 모델을 이용하여 구현하라."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_B4U3Q_o_rv"
      },
      "source": [
        "C. 과제 1에서 구현한 자신의 알고리즘과 사이킷런에서 제공하는 LogisticRegression 모델의 성능을 비교하라."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLgHDQGJYSOa"
      },
      "source": [
        "단, 모델 구현에 필요한 사진을 직접 구해야 한다. 최소 100장 이상의 사진 활용할 것."
      ]
    }
  ]
}